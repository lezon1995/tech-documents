# 分布式缓存

## 1 Redis和Memcached有什么区别?

1. redis支持服务端的数据操作; Memcached需要将数据取回到客户端修改后再set回去;
2. **redis拥有更丰富的数据结构与操作api**
3. 使用简单的key-value存储的话,Memcached的内存利用率更高,但是如果使用hash结构的话,Redis的内存利用率更高
4. **Redis是单线程模型 ,Memcached可以使用多线程模型,所以在存储小数据的时候Redis性能更高**
5. **Memcached不支持原生的集群模式,但是Redis支持原生集群模式**



## redis的线程模型是什么？

### 单线程模型

#### 1）文件事件处理器 File Event Handler


 redis基于reactor模式开发了网络事件处理器，这个处理器叫做**文件事件处理器**，file event handler。**<u>这个文件事件处理器，是单线程的，redis才叫做单线程的模型</u>**，采用**IO多路复用机制同时监听多个socket**，根据socket上的事件来选择对应的事件处理器来处理这个事件。

 

如果被监听的socket准备好执行**accept**、**read**、**write**、**close**等操作的时候，跟操作对应的文件事件就会产生，这个时候文件事件处理器就会调用之前关联好的事件处理器来处理这个事件。

 

文件事件处理器是单线程模式运行的，但是通过IO多路复用机制监听多个socket，可以实现高性能的网络通信模型，又可以跟内部其他单线程的模块进行对接，保证了redis内部的线程模型的简单性。

 

**文件事件处理器**的结构包含**4个部分**：**多个socket**，**IO多路复用程序**，**文件事件分派器**，**事件处理器**（命令请求处理器、命令回复处理器、连接应答处理器，等等）。

 **事件处理器**包含:

- **连接应答 处理器**

  > 处理socket的**<u>连接</u>**请求

- **命令请求 处理器**

  > 处理socket的**<u>读写</u>**请求

- **命令回复 处理器**

  > 将socket的读写请求后的**<u>结果返回</u>**

多个socket可能并发的产生不同的操作，每个操作对应不同的文件事件，但是IO多路复用程序会监听多个socket，但是会**将socket放入一个队列中排队**，每次从队列中**取出一个socket给事件分派器**，事件分派器把socket给对应的事件处理器。

 

然后一个socket的事件处理完之后，IO多路复用程序才会将队列中的下一个socket给事件分派器。文件事件分派器会根据每个socket当前产生的事件，来选择对应的事件处理器来处理。

 

#### 2）文件事件

 

当socket变得**可读**时（比如客户端对redis执行write操作，或者close操作），或者有新的可以应答的socket出现时（客户端对redis执行connect操作），socket就会产生一个**AE_READABLE**事件。

 

当socket变得**可写**的时候（客户端对redis执行read操作），socket会产生一个**AE_WRITABLE**事件。

 

IO多路复用程序可以<u>同时监听**AE_REABLE**和**AE_WRITABLE**两种事件</u>，**要是一个socket同时产生了AE_READABLE和AE_WRITABLE两种事件**，那么**文件事件分派器优先处理<u>AE_REABLE</u>事件**，然后才是**<u>AE_WRITABLE</u>**事件。

 

#### 3）文件事件处理器

 

如果是客户端要连接redis，那么会为socket关联------------------**连接应答处理器**

如果是客户端要写数据到redis，那么会为socket关联------------------**命令请求处理器**

如果是客户端要从redis读数据，那么会为socket关联------------------**命令回复处理器**

 

#### 4）客户端与redis通信的一次流程

 

在redis启动初始化的时候，redis会将连接应答处理器跟AE_READABLE事件关联起来，接着如果一个客户端跟redis发起连接，此时会产生一个**AE_READABLE**事件，然后由连接应答处理器来处理跟客户端建立连接，创建客户端对应的socket，同时将这个socket的**AE_READABLE**事件跟命令请求处理器关联起来。



当客户端向redis发起请求的时候（**不管是读请求还是写请求，都一样**），首先就会在socket产生一个**AE_READABLE**事件，然后由对应的命令请求处理器来处理。这个命令请求处理器就会从socket中读取请求相关数据，然后进行执行和处理。


接着redis这边准备好了给客户端的响应数据之后，就会将socket的**AE_WRITABLE**事件跟命令回复处理器关联起来，当客户端这边准备好读取响应数据时，就会在socket上产生一个**AE_WRITABLE**事件，会由对应的命令回复处理器来处理，就是将准备好的响应数据写入socket，供客户端来读取。

 

命令回复处理器写完之后，就会**删除**这个socket的**AE_WRITABLE**事件和命令回复处理器的关联关系。

 

## 为什么redis是单线程的但是还可以支撑高并发？

### 1）纯内存操作

### 2）核心是基于非阻塞的IO多路复用机制

### 3）单线程反而避免了多线程的频繁上下文切换问题



## redis都有哪些数据类型？分别在哪些场景下使用比较合适？

### （1）string

这是最基本的类型了，没啥可说的，就是普通的set和get，做简单的kv缓存

 

### （2）hash

这个是类似map的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是这个对象没嵌套其他的对象）给缓存在redis里，然后每次读写缓存的时候，可以就操作hash里的某个字段。

 

key=150

 

value={

  “id”: 150,

  “name”: “zhangsan”,

  “age”: 20

}

 

hash类的数据结构，主要是用来存放一些对象，把一些简单的对象给缓存起来，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值

 

value={

  “id”: 150,

  “name”: “zhangsan”,

  “age”: 21

}

 

 

### （3）list

有序列表，这个是可以玩儿出很多花样的

 

微博，某个大v的粉丝，就可以以list的格式放在redis里去缓存

 

key=某大v

 

value=[zhangsan, lisi, wangwu]

 

比如可以通过list存储一些列表型的数据结构，类似粉丝列表了、文章的评论列表了之类的东西

 

比如可以通过lrange命令，就是从某个元素开始读取多少个元素，可以基于list实现分页查询，这个很棒的一个功能，基于redis实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页一页走

 

比如可以搞个简单的消息队列，从list头怼进去，从list尾巴那里弄出来

 

### （4）set

无序集合，自动去重

 

直接基于set将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全局去重，你当然也可以基于jvm内存里的HashSet进行去重，但是如果你的某个系统部署在多台机器上呢？

 

得基于redis进行全局的set去重

 

可以基于set玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看俩人的共同好友是谁？对吧

 

把两个大v的粉丝都放在两个set中，对两个set做交集

 

### （5）sorted set

排序的set，去重但是可以排序，写进去的时候给一个分数，自动根据分数排序，这个可以玩儿很多的花样，最大的特点是有个分数可以自定义排序规则

 

比如说你要是想根据时间对数据排序，那么可以写入进去的时候用某个时间作为分数，人家自动给你按照时间排序了

 

排行榜：将每个用户以及其对应的什么分数写入进去，zadd board score username，接着zrevrange board 0 99，就可以获取排名前100的用户；zrank board username，可以看到用户在排行榜里的排名

 

zadd board 85 zhangsan

zadd board 72 wangwu

zadd board 96 lisi

zadd board 62 zhaoliu

 

96 lisi

85 zhangsan

72 wangwu

62 zhaoliu

 

zrevrange board 0 3

 

获取排名前3的用户

 

96 lisi

85 zhangsan

72 wangwu

 

zrank board zhaoliu

4



## redis的过期策略都有哪些？

- ### 定期删除

  > redis默认每隔100ms就**随机抽取**一些设置了过期时间的key，检查其是否过期，如果过期就删除。
  >
  > 假设redis里放了10万个key，都设置了过期时间，你每隔几百毫秒，就检查10万个key，那redis基本上就死了，cpu负载会很高的，消耗在你的检查过期key上了。
  >
  > 注意这里可不是每隔100ms就遍历所有的设置过期时间的key，那样就是一场性能上的灾难。实际上redis是每隔100ms随机抽取一些key来检查和删除的。

- ### 惰性删除

  > 惰性删除了就是说在你获取某个key的时候，redis会检查一下 ，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除，不会给你返回任何东西。

  #### 一般是配合**定期删除**和**惰性删除**一起使用

## 内存淘汰机制都有哪些？

1. **no-eviction**：当内存不足以容纳新写入数据时，**<u>新写入操作会报错</u>**，这个一般没人用吧，实在是太恶心了
2. **allkeys-lru**：当内存不足以容纳新写入数据时，在**所有键空间**中，移除最近**最少使用的key**（**<u>这个是最常用的</u>**）
3. **allkeys-random**：当内存不足以容纳新写入数据时，在**所有键空间**中，**随机移除某个key**，这个一般没人用吧，为啥要随机，肯定是把最近最少使用的key给干掉啊
4. **volatile-lru**：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，移除最近最少使用的key（这个一般不太合适）
5. **volatile-random**：当内存不足以容纳新写入数据时，在**设置了过期时间的键空间**中，随机移除某个key
6. **volatile-ttl**：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除



## 手写一下LRU代码实现？

### API实现

```java
import java.util.LinkedHashMap;
import java.util.Map;

public class LRULinkedHashMap<K, V> extends LinkedHashMap<K, V> {
    //定义缓存的容量
    private int cacheSize;

    //带参数的构造器
    LRULinkedHashMap(int cacheSize) {
        //如果accessOrder为true的话，则会把访问过的元素放在链表后面，放置顺序是访问的顺序
        //如果accessOrder为flase的话，则按插入顺序来遍历
        super((int) Math.ceil(cacheSize / 0.75f) + 1, 0.75f, true);
        //传入指定的缓存最大容量
        this.cacheSize = cacheSize;
    }

    //实现LRU的关键方法，如果map里面的元素个数大于了缓存最大容量，则删除链表的顶端元素
    @Override
    public boolean removeEldestEntry(Map.Entry<K, V> eldest) {
        return size() > cacheSize;
    }

    @Override
    public String toString() {
        StringBuilder stringBuilder = new StringBuilder();
        for (Map.Entry<K, V> entry : this.entrySet()) {
            stringBuilder.append(String.format("[ %s : %s ]\n", entry.getKey(), entry.getValue()));
        }
        return stringBuilder.toString();
    }

    //test
    public static void main(String[] args) {
        LRULinkedHashMap<String, Integer> testCache = new LRULinkedHashMap<>(3);
        testCache.put("A", 1);
        testCache.put("B", 2);
        testCache.put("C", 3);
//        System.out.println(testCache.get("B"));
//        System.out.println(testCache.get("A"));
        testCache.put("D", 4);
        testCache.put("E", 5);
        System.out.println(testCache);
    }
}
```

### 原生实现

```java
import java.util.HashMap;

/**
 * 使用cache和链表实现缓存
 */
public class LRU2<K, V> {
    /**
     * 最大缓存大小
     */
    private final int MAX_CACHE_SIZE;
    /**
     * 头结点
     */
    private Entry<K, V> head;
    /**
     * 尾节点
     */
    private Entry<K, V> tail;

    /**
     * 缓存map
     */
    private HashMap<K, Entry<K, V>> cacheMap;

    public LRU2(int cacheSize) {
        MAX_CACHE_SIZE = cacheSize;
        cacheMap = new HashMap<>();
    }

    public void put(K key, V value) {
        Entry<K, V> entry = getEntry(key);
        //如果是新添加的元素
        if (entry == null) {
            //如果缓存大小>=最大指定大小
            if (cacheMap.size() >= MAX_CACHE_SIZE) {
                //从缓存中删除尾节点的元素
                cacheMap.remove(tail.key);
                //去掉尾节点
                removeTail();
            }
            //创建新节点
            entry = new Entry<>();
            entry.key = key;
            entry.value = value;
            //将每次新增的节点都放到头结点
            moveToHead(entry);
            //并且添加到缓存中
            cacheMap.put(key, entry);
        } else {
            //如果是缓存中已经存在的元素 则直接赋值
            entry.value = value;
            //将每次新增的节点都放到头结点
            moveToHead(entry);
        }
    }

    /**
     * 根据键获取值
     *
     * @param key
     * @return
     */
    public V get(K key) {
        Entry<K, V> entry = getEntry(key);
        if (entry == null) {
            return null;
        }
        //将每次操作过的节点放到头结点位置
        moveToHead(entry);
        return entry.value;
    }

    /**
     * 移除当前Key
     *
     * @param key
     */
    public void remove(K key) {
        //获取当前Key的Value
        Entry<K, V> entry = getEntry(key);
        //如果value存在
        if (entry != null) {
            //如果value为头结点
            if (entry == head) {
                Entry<K, V> next = head.next;
                //让当前头结点的下一个节点为空
                head.next = null;
                //让之前头结点的下一个节点为新的头结点
                head = next;
                //让当前头结点的前一个节点为空
                head.pre = null;
            } else if (entry == tail) {//如果当前需要删除的节点为尾节点
                Entry<K, V> prev = tail.pre;
                //让当前尾节点的前一个节点为空
                tail.pre = null;
                //让旧的尾节点的前一个节点为新的尾节点
                tail = prev;
                //让当前尾节点的下一个节点为空
                tail.next = null;
            } else {//如果当前需要删除的节点为中间节点
                //直接让当前删除的节点的上一个节点的next指向当前删除的节点的下一个节点
                entry.pre.next = entry.next;
                //直接让当前删除的节点的下一个节点的pre指向当前删除的节点的上一个节点
                entry.next.pre = entry.pre;
            }
            //从缓存map中删除该键
            cacheMap.remove(key);
        }
    }

    /**
     * 移除尾节点
     */
    private void removeTail() {
        //如果尾节点不为空
        if (tail != null) {
            //让尾节点的前一个节点=prev
            Entry<K, V> prev = tail.pre;
            //如果尾节点的前一个节点为空 说明整个链表就一个节点
            if (prev == null) {
                //让头尾节点都为空
                head = null;
                tail = null;
            } else {
                //如果尾节点的前一个节点不为空
                //让尾节点与前一个节点断开
                tail.pre = null;
                //让prev为当前链表的尾节点
                tail = prev;
                //让prev的下一个节点为空(之前引用着已经删除了的尾节点)
                tail.next = null;
            }
        }
    }

    /**
     * 将参数节点放到头结点
     * 此时置于尾端的节点就是访问次数最少的节点 应该被淘汰掉
     * 符合LRU算法思想
     *
     * @param entry 参数节点
     */
    private void moveToHead(Entry<K, V> entry) {
        //如果当前节点已经为头结点 直接结束
        if (entry == head) {
            return;
        }
        //如果当前头尾节点都为空 说明整个链表为空
        if (head == null || tail == null) {
            //即让头尾节点都为当前节点entry
            head = tail = entry;
            return;
        }

        //如果当前节点的前一个节点不为空
        if (entry.pre != null) {
            //让当前节点的前一个节点的next指向当前节点的下一个节点
            // 比如 A->-B->C 现在将B移到头结点 那么B与A C断开 即为 A->C
            entry.pre.next = entry.next;
        }
        //如果当前节点的下一个节点不为空
        if (entry.next != null) {
            //让当前节点的下一个节点的pre指向当前节点的前一个节点
            entry.next.pre = entry.pre;
        }
        //如果当前节点即为尾节点
        if (entry == tail) {
            //让prev为尾节点的前一个节点
            Entry<K, V> prev = entry.pre;
            //如果尾节点的前一个节点不为空
            if (prev != null) {
                //让尾节点的前一个节点为空
                tail.pre = null;
                //让prev为当前尾节点
                tail = prev;
                //让prev的下一个节点为空
                tail.next = null;
            }
        }

        entry.next = head;
        head.pre = entry;
        entry.pre = null;
        head = entry;
    }

    private Entry<K, V> getEntry(K key) {
        return cacheMap.get(key);
    }

    private static class Entry<K, V> {
        Entry<K, V> pre;
        Entry<K, V> next;
        K key;
        V value;
    }

    @Override
    public String toString() {
        StringBuilder stringBuilder = new StringBuilder();
        Entry<K, V> entry = head;
        stringBuilder.append("head >> ");
        while (entry != null) {
            stringBuilder.append(String.format("%s:%s ", entry.key, entry.value));
            entry = entry.next;
        }
        stringBuilder.append(" >> tail");
        return stringBuilder.toString();
    }

    public static void main(String[] args) {
        LRU2<Integer, Integer> lru2 = new LRU2<>(5);
        lru2.put(1, 1);
        System.out.println(lru2);
        lru2.put(2, 2);
        System.out.println(lru2);
        lru2.put(3, 3);
        System.out.println(lru2);
        lru2.get(1);
        System.out.println(lru2);
        lru2.put(4, 4);
        lru2.put(5, 5);
        lru2.put(6, 6);
        System.out.println(lru2);
    }
}
```

## 如何保证Redis的高并发和高可用？



## redis的主从复制原理能介绍一下么？



## redis的哨兵原理能介绍一下么？