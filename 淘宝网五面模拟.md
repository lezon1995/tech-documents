# 淘宝网五面模拟

## 淘宝一面: 

**面试介绍**

1）自我介绍？

2）项目介绍？

3）遇到的最大困难是什么？怎么解决的？

4）你觉得你能怎么优化这个项目？

**面试题目**

1）讲一下JVM

> JVM是java中非常重要的一部分，java之所以能够跨平台，是因为JVM。
>
> JVM在内存中构建了一个虚拟的java内存模型，又叫JMM
>
> `JMM`由堆、栈、方法区、本地方法栈、程序计数器

2）讲一下JVM的分代回收以及具体算法

> JVM中有复制、标记清除、标记整理、分代回收算法，
>
> 其中分代回收算法是将堆内存分为连续的年轻代，连续的老年代，然后年轻代又分为`eden`，2个`survivor`区，在年轻代当中，是采用复制算法，每当产生垃圾回收的时候，会将eden区的存活对象全部移动到`survivor0`区，然后清空eden区，第二次GC的时候，又将`eden`和`survivor0`中的存活对象复制到`survivor1`区中，然后清空`eden`和`survivor0`，如此反复复制清空，当某个survivor区不足以存放这次存活的对象的时候，就会将这次存活的对象放入到老年代中，在老年代中，采用的是标记整理算法，随着老年代不断地被放入存活对象，老年代开始装不下新的存活对象，此时就会触发一次Full GC，整个年轻代和老年代全部GC，老年代中会通过一次扫描，此时会让工作线程停顿一段时间，成为STW，扫描完之后，会清空所有垃圾对象，并将标记存活的对象全部移动到内存的一端，以腾出连续的空间，

3）将一下JVM的垃圾收集器，G1和CMS有啥区别？

> 垃圾收集器有七种
>
> 新生代
>
> - serial串行垃圾回收器（复制算法）
> - parallel new 并行垃圾回收器（复制算法）
> - parallel scavenge 并行垃圾回收器，追求高吞吐量
>
> 老年代
>
> - serial old串行垃圾回收器（标记整理）
> - parallel old并行垃圾回收器（标记整理）
> - CMS 并发标记清除（标记清理）
>
> 新生代老年代兼顾
>
> - G1垃圾回收器（标记整理）
>
> CMS追求低停顿，只存在于老年代，使用标记清除算法，并发清除，有四个过程
>
> 1. 初始标记 标记了从`GC Root`开始直接可达的对象 `STW` 
> 2. 并发标记 与工作线程一起运行，从`GC Root`开始对堆中对象进行可达性分析，找出存活对象
> 3. 重新标记 标记那些在`并发标记`阶段发生变化的对象 `STW`
> 4. 并发清除 与工作线程一起运行，清除掉垃圾对象
>
> CMS使用的是标记清除算法，所以在回收后会产生内存碎片，可以指定JVM参数让回收后进行碎片整理
>
> 
>
> G1垃圾回收器是兼顾新生代和老年代的垃圾回收器，它会将内存分成相等大小的区域，不要求新生代和老年代内存连续，采用多个线程并行回收，因为采用标记整理算法，所以不会产生内存碎片，而且分区之后可以选择性回收，优先收集垃圾较多的区域。
>
> 它的回收过程跟CMS差不多
>
> 也是大致四步
>
> 1. 初始标记 标记了从`GC Root`开始直接可达的对象 `STW` 
> 2. 并发标记 与工作线程一起运行，从`GC Root`开始对堆中对象进行可达性分析，找出存活对象
> 3. 最终标记 标记那些在`并发标记`阶段发生变化的对象 `STW`
> 4. 筛选回收 G1收集器会根据区域的垃圾程度进行排序，根据用户所期待的GC停顿时间回收一部分区域

4）讲一下一个变量从产生到结束所经历的过程，讲一下字符串常量的过程？

5）将一下线程安全问题产生的原因？

6）讲一下乐观锁和悲观锁

7）乐观锁是怎么保证一致性的

8）Integer和int有啥区别，integer中有哪些特殊的函数？

> 静态compare 比较两个数大小
>
> lowestOneBit 获取最低位
>
> highestOneBit 获取最高位
>
> max 返回两个数中大的那个
>
> min 返回两个数中小的那个

9）讲一下数据库的隔离等级

10）说一下MVCC

> MVCC全称是`Multi Version Currency Control`，多版本并发控制，是数据库实现`事务隔离`的一种方案
>
> 还有一种方案是LBCC，`Lock Based Currency Control`，这种方案是基于行锁来实现的，用锁的并发度太低，不支持读写并发操作
>
> MVCC是基于请求时间点的数据快照实现的，主要通过数据的`版本号`和`事务ID`，还有`回滚指针`，在innodb数据库中，每一个行数据都会有三个默认隐藏的字段，`DB_TRX_ID`事务ID，`DB_ROLL_PTR`回滚指针，`DELETE_BIT`删除标志位
>
> 每次开启一个事务，然后更新数据（`insert`，`update`，`delete`），都会往undo log中记录一条`反操作`日志，当不同的事务访问同一条数据的时候，会查看它的`回滚指针`是否为空，如果不为空，代表当前该数据已经处于某个事务当中，然后就会去读取它回滚之后的数据，以保证不同事务的数据隔离性

11）说一聚簇索引和非聚簇索引的有什么不同

> 官方的说
>
> 聚簇索引是指 `索引的逻辑顺序`与`数据的物理顺序`一致
>
> 非聚簇索引  `索引的逻辑顺序`与`数据的物理顺序`不一致
>
> 通俗的说
>
> 聚簇索引是指 索引与数据存在同一个文件当中
>
> 非聚簇索引是指 索引与数据存在不同的文件当中

## 淘宝二面: 

1、问了冒泡排序，快排，和归并排序及优缺点和优化

> `冒泡`排序，每轮左右比较交换得到一个最大的值放在最右边，`优点`：稳定，`缺点`：交换次数多，数据量起来之后比较耗时，`优化`：可以减少交换的次数，采用增量缩减的方式，也就是希尔排序
>
> `快速`排序，让数组右边的值全部大于左边的值，然后在两边数组中继续采用刚刚的操作细分，`优点`：时间复杂度`O(nlogn)`较小，交换次数较少，`缺点`：不稳定，使用到了递归，所以需要额外栈空间，空间换时间，`优化`：这个排序已经非常快了，我没想出来还有哪些地方需要优化
>
> `归并`排序：采用分治思想，将数组一分为二，二分为四，如果递归，最终解决每个最小单位的排序问题，然后在合并，再解决，再合并，最终得到排序后的数组，`优点`：稳点，速度快，时间复杂度`O(nlogn)`较小，`缺点`：同样用到了递归思想，需要额外栈空间，空间换时间

2，网络方面有osi七层，tcp/ip五层，分别有哪些协议及作用

> 1. 应用层（http，ftp）
> 2. 表现层
> 3. 会话层（RPC）
> 4. 运输层（TCP UDP）
> 5. 网络层（IP）
> 6. 数据链路层
> 7. 物理层

3，爬虫用的什么数据结构

4、tcp的流量控制和拥塞控制

> 在TCP连接阶段，客户端与服务端会协商滑动窗口的尺寸
>
> 发送方根据协商的结果，发送确定大小后的数据字节流，并且等待对方确认
>
> 发送方根据确认信息，改变窗口的尺寸，发送未得到确认的字节流
>
> 如果出现发送拥塞，发送窗口减短一半，超时重传时长增大一倍
>
> 
>
> 拥塞控制
>
> TCP在传输过程中，为了防止过量的数据注入网络，使网络中的链路不超出负载，以此来提高网络利用率，降低丢包率，并保证网络资源对每条数据流的公平性。
>
> 拥塞控制包含四个部分
>
> - 慢启动
> - 拥塞避免
> - 快速重传
> - 快速恢复

5，mysql用的什么存储引擎，这个存储引擎用的什么数据结构 ，有哪些优缺点，怎么使用

6，jvm的垃圾回收机制和垃圾收集器

7、spring当中事物的隔离级别

8、jdk1.8 concurrenthashmap 的新的特性，有没有看过源码

9、 threadlocal了解吗

10，问了redis的一些问题，项目中有(扩容，失效key清理策略等)

11，剩下的都是项目的东西(kafka filebeat elk原理，主从选举，复制等)

12，后面扩展的问了一些大数据相关的，问我一些大数据处理框架是否有了解

整个过程四十分钟左右

## 淘宝三面 

主要项目，你做过哪些项目，用过哪些技术？了解哪些框架？你觉得对你技术提升最高的是哪一件事情，提升了你哪一方面的技术？

1）讲一下Spring AOP和IOC的底层实现

2）说一下hashcode的作用？HashMap的底层实现？HashMap和HashTable的区别

3）说一下concurrentHashMap和hashTable在性能上的区别？以及这种差异形成的原因

4）讲一下堆以及堆排序

> 堆排序是利用了大顶堆的数据结构的特点，父节点总是大于其子节点
>
> 通过将一个无序数组来表示一个堆结构，然后构建大顶堆，这是根节点就是最大的数，然后将根节点的数跟数组末尾的数交换
>
> 然后再在剩下的数中找出一个最大的数，也就是第二大的数，然后再跟数组末尾元素交换，反复循环，这就是堆排序的思想

5）说一下B+tree和二叉搜索树的区别？说一下二叉搜索树和AVL树、红黑树之间的差别

> 二叉搜索树的特点是左节点>父节点>右节点，没有高度差的限制，这样一来，如果数据从小到大的插入的话，那么这个二叉树就会变成一个链表，查询时间复杂度到了`O(n)`
>
> AVL树是`平衡二叉搜索树`的一种，它有一个条件就是左右子树的高度差不能超过1，如果超过了就会通过子树的左旋右旋来满足高度差不能超过1，这样可以使得AVL树总可以保证树的查询时间复杂度在`O(logn)`
>
> 红黑树也是`平衡二叉搜索树`的一种，它是通过控制节点的颜色，来维护树的结构使其查询复杂度在`O(logn)`，按理说`AVL树`和`红黑树`都可以很好的保证树的结构不受数据的影响，但是为什么`hashmap`中采用`红黑树`来实现呢？
>
> 因为hashmap一般对数据的增删比较多，`AVL数`在数据量比较多的时候，新增节点会导致树进行`旋转`操作，有时候会`旋转`很多次，影响增删的性能，但是`红黑树`不管多少数据，新增数据最多`2次旋转`，删除数据最多`3次旋转`就可以达到平衡状态，比较稳定，在查询效率都一样的情况下，所以选择红黑树。

6）给你两个文件（字符串形式的）如何找出他们之间的不同地方？

7）你刚刚说的能怎么优化？

## 淘宝四面 交叉面 

本来以为三面结束就是hr面了，又收到一面交叉面

1. 给你50亿行字符串，机器4G内存（只能一台机器），找出重复次数最多的那行字符串？（以行为单位，每行不超过10个字符）
2. 设计一个算法，实现两个10g大文件在10m的内存中将两个大文件中重复的放进第三个文件

3. 快速排序的平均复杂多少？最坏情况是什么？（这个题估计就是缓和一下尴尬的气氛）

## 淘宝五面 hr 

大概问了

1，介绍一个对于你来讲成长最大的项目，你在项目中承担的作用

2，对阿里有没有了解

3，对电子商务有没有了解

4，了解新零售吗

5，电子商务和新零售有什么区别

6，还有哪些电子商务平台 国内外

7，用过哪些算法模型

8，读过哪些算法方面的书籍

9，开放题 数据和商业的关系